Build the container image:
$ docker build . -t gpuplug-test -f=Dockerfile

Start the host server:
# ./gpuplugd.py

This creates a UNIX domain socket /tmp/gpuplug-ctl. This process needs
to access the sysfs of the system and is run as root for that reason.

Start the container:
$ docker run -it --mount type=bind,source="$(./gpuplug-ctl.py)",target=/tmp/gpuplug gpuplug-test bash

Here gpuplug-ctl.py requests a new socket from gpuplugd.py via
/tmp/gpuplug-ctl for communication between the container and gpuplugd.py
running on the host system. The name of the container communication
socket is printed by gpuplug-ctl.py and the socket is bind mounted into
the container by Docker.

Bind a GPU from the container:
# gpuplug.py get

Request a device binding from gpuplugd.py running on the host via the
bind mounted socket.

And release it:
# gpuplug.py put

Notes and caveats:
- The user space portion of the GPU driver stack running in the
  container should match the version of the kernel part installed on the
  host. This is because containers aren't real virtual machines and they
  share the kernel drivers of the host.
    - The Dockerfile in this repository installs 418.67 version of the
      NVIDIA driver and it most likely won't work unless it matches with
      the host driver version.
