Build the container image:
$ docker build . -t gpuplug-test -f=Dockerfile.cuda-10.1

Start the host server:
# ./gpuplugd.py

This creates a UNIX domain socket /tmp/gpuplug. The gpuplugd server
needs to access the sysfs of the system and is run as root because of
that.

Start the container:
$ docker run -it --mount type=bind,source=/tmp/gpuplug,target=/tmp/gpuplug gpuplug-test bash

The gpuplug server socket is bind mounted to the container to enable
communication between the server running on the host and the client
running in the container.

Bind a GPU from the container:
# gpuplug.py get

And release it:
# gpuplug.py put

Notes and caveats:
- The user space portion of the GPU driver stack running in the
  container should match the version of the kernel part installed on the
  host. This is because containers aren't real virtual machines and they
  share the kernel drivers of the host.
    - The Dockerfile in this repository installs 418.67 version of the
      NVIDIA driver and it most likely won't work unless it matches with
      the host driver version.
